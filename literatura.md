Template:
1. Prezime, Ime; Prezime2, Ime2; Prezime 3, Ime 3: “Naslov knjige“, Izdavač, mjesto izdavanja, godina
2. Prezime, Ime; Prezime2, Ime2; Prezime 3, Ime 3: “Naslov članka“, Ime časopisa, Izdavač, mjesto izdavanja, godina
3. Prezime, Ime: Naslov, s Interneta, http://adresa.xx, točan datum


[book_articulation] Allen, Jont B. : "Articulation and Intelligibility", Morgan & Claypool, SAD, 2005., str. 2,

[book_springer] Benetsy, Jacob; Sondhi, M. Mohan; Huang, Yiteng : "Springer Handbook of Speech Processing", Springer-Verlag, Berlin, 2008., str. 843-845

[book_asa] Bregman, Albert S. : "Auditory Scene Analysis : The Perceptual Organization of Sound", MIT Press; Cambridge, Massachusetts; 1994.

[book_casa] Wang, DeLiang; Brown; Guy J. : "Computational Auditory Scene Analysis: Principles, Algorithms, and Applications", John Wiley & Sons, Inc., New Jersey, 2006.

[book_human_machine] Divenyi, Pierre: "Speech Separation by Humans and Machines", Kluwer Academic Publishers, Boston, 2005.

[book_nn_sp] Hu, Yu Hen; Hwang, Jenq-Neng: "Handbook of Neural Network Signal Processing", CRC Press, Boca Raton, 2002., str. 184, 180


[chime_data] Vincent, E.; Barker, J.; Watanabe, S.; Le Roux, J.; Nesta, F; Matassoni, M. :
The second CHiME Speech Separation and Recognition Challenge: Datasets, tasks and baselines,
Proceedings of IEEE International Conference on Acoustics, Speech, and Signal Processing, Vancouver, 2013.

[chime_cite2] Barker, J.P.; Vincent, E.; Ma, N.; Christensen, H.; Green, P.D.: "The PASCAL CHiME Speech Separation and Recognition Challenge", Computer Speech and Language, Elsevier, 2013, str. 621-633

[chime_overview] Vincent, E.; Barker, J. ; Watanabe, S. ; Le Roux, J. ; Nesta, F. ; Matassoni, M. : "The second ‘CHiME’ speech separation and recognition challenge: An overview of challenge systems and outcomes",
IEEE Workshop on Automatic Speech Recognition and Understanding (ASRU), IEEE, Olomouc, 2013, str. 162-167

[book_speech_enhancement] Loizou, Philipos C.: "Speech Enhancement: Theory and Practice, 2nd Edition", CRC Press, Boca Raton, 2013, str. 609

[chime_grid_cite] Cooke, Martin; Barker, Jon; Cunningham, Stuart; Shao, Xu: "An audio-visual corpus for speech perception and automatic
speech recognition", The Journal of the Acoustical Society of America, Acoustical Society of America, SAD, 2006.

[chime_website] "The 2nd 'CHiME' Speech Separation and Recognition Challenge: Small vocabulary track", http://spandh.dcs.shef.ac.uk/chime_challenge/chime2013/chime2_task1.html, 25.6.2015

[book_htk] Young, Steve; Evermann, Gunnar; Gales, Mark; Hain, Thomas; Kershaw, Dan; Liu, Xunying (Andrew); Moore, Gareth; Odell, Julian; Ollason, Dave; Povey, Dan; Valtchev, Valtcho; Woodland,  Phil : "The HTK Book", Cambridge University Engineering Department, http://htk.eng.cam.ac.uk/docs/docs.shtml, 2009., str.80

[chime_readme] Vincent, Emanuel: "The 2nd CHiME Challenge Baseline scoring, decoding and training scripts", http://spandh.dcs.shef.ac.uk/chime_challenge/chime2013/grid/README.pdf, 2012., 25.6.2015

[book_opensmile] Eyben, Florian; Weninger, Felix; Wollmer, Martin; Schuller, Bjorn: "openSMILE: open-Source Media Interpretation by Large feature-space Extraction", http://www.audeering.com/research-and-open-source/files/openSMILE-book-latest.pdf, str. 32, 25.6.2015.

[book_bss_ica] Comon, Pierre; Jutten, Christian: "Handbook of Blind Source Separation: Independent Component Analysis and Applications", Academic Press, Oxford, 2010., str. 7-9, 515

[dnn_faster_nmf] Liu, Ding; Smaragdis, Paris; Kim, Minje: "Experiments on Deep Learning for Speech Denoising", Proceedings of the annual conference of the International Speech Communication Association (INTERSPEECH), Singapore, 2014.

[wen_chime_pobjednik] Geiger, Jürgen T.; i drugi: "The TUM+ TUT+ KUL approach to the 2nd CHiME challenge: Multi-stream ASR exploiting BLSTM networks and sparse NMF.", Proc. of CHiME, 2013.

[dnn_nmf] Kang, Tae Gyoon; i drugi: "NMF-based Target Source Separation Using Deep Neural Network", Signal Processing Letters, IEEE, 2015.

[dnn_vs_nmf_novo] Huang, Po-Sen; Kim, Minje; Hasegawa-Johnson, Mark; Smaragdis, Paris: "Joint Optimization of Masks and Deep Recurrent Neural Networks for Monaural Source Separation", IEEE TRANSACTIONS ON AUDIO, SPEECH, AND LANGUAGE PROCESSING, 2015.

[deep_nmf] Le Roux, Jonathan; Hershey, John R.; Weninger, Felix: "Deep NMF for Speech Separation", http://www.jonathanleroux.org/pdf/LeRoux2015ICASSP04DeepNMF.pdf, 2015.

[ang_banko_brill_scale] Banko, Michele; Brill, Eric: "Scaling to very very large corpora for natural language disambiguation", Proceedings of the 39th Annual Meeting on Association for Computational Linguistics, Association for Computational Linguistics, 2001.

[ang_coates_model_size] Coates, Adam; Ng, Andrew Y.; Lee, Honglak: "An analysis of single-layer networks in unsupervised feature learning", International conference on artificial intelligence and statistics, 2011.

[ang_cudnn] Chetlur, Sharan; Woolley, Cliff; Vandermersch, Philippe; Cohen, Jonathan; Tran, John; Catanzaro, Bryan; Shelhamer, Evan: "cudnn: Efficient primitives for deep learning", arXiv preprint arXiv:1410.0759, 2014.

[ang_cots_hpc] Coates, Adam; Huval, Brody; Wang, Tao; Wu, David; Catanzaro, Bryan; Andrew, Ng: "Deep learning with COTS HPC systems", Proceedings of the 30th international conference on machine learning, 2013.

[ang_deep_speech] Hannun, Awni; i drugi: "DeepSpeech: Scaling up end-to-end speech recognition.", arXiv preprint arXiv:1412.5567, 2014.

[graves14] Graves, Alex; Jaitly, Navdeep: "Towards end-to-end speech recognition with recurrent neural networks." Proceedings of the 31st International Conference on Machine Learning (ICML-14), 2014.

[dnn_turci] Grais, Emad M.; Sen, Mehmet Umut; Erdogan, Hakan: "Deep neural networks for single channel source separation." Acoustics, Speech and Signal Processing (ICASSP), 2014 IEEE International Conference on. IEEE, 2014.

[dnn_wang_ss_frontend] Narayanan, Arun; Wang, DeLiang: "Investigation of speech separation as a front-end for noise robust speech recognition", Audio, Speech, and Language Processing, IEEE/ACM Transactions on, IEEE, 2014.

[dnn_rnn_smaragdis]  Huang, Po-Sen; Kim, Minje; Hasegawa-Johnson, Mark; Smaragdis, Paris: "Deep learning for monaural speech separation", Acoustics, Speech and Signal Processing (ICASSP), 2014 IEEE International Conference on, IEEE, 2014.

[dnn_kinezi] Xu, Yong; Du, Jun; Dai, Li-Rong; Lee, Chin-Hui: "An experimental study on speech enhancement based on deep neural networks", Signal Processing Letters, IEEE, 2014.

[dnn_multitalker] Weng, Chao; Yu, Dong; Seltzer, Michael L.; Droppo, Jasha: "Single-channel mixed speech recognition using deep neural networks", Acoustics, Speech and Signal Processing (ICASSP), 2014 IEEE International Conference on, IEEE. 2014.

[dnn_music] Huang, Po-Sen; Chen, Scott Deeann; Smaragdis, Paris; Hasegawa-Johnson, Mark: "Singing-voice separation from monaural recordings using robust principal component analysis", Acoustics, Speech and Signal Processing (ICASSP), 2012 IEEE International Conference on, IEEE, 2012.

[wen_chime13] Weninger, Felix; Geiger, Jurgen; Wollmer, Martin; Schuller, Bjorn; Rigoll, Gerhard: "The Munich feature enhancement approach to the 2nd CHiME challenge using BLSTM recurrent neural networks", Proceedings of the 2nd CHiME workshop on machine listening in multisource environments, Citeseer, 2013.

[wen_chime14] Weninger, Felix; Geiger, Jurgen; Wollmer, Martin; Schuller, Bjorn; Rigoll, Gerhard: "Feature enhancement by deep LSTM networks for ASR in reverberant multisource environments", Computer Speech & Language, Elsevier, 2014

[wen_sdr_lstm] Weninger, Felix; Hershey, John R.; Le Roux, Jonathan; Schuller, Bjorn: "Discriminatively trained recurrent neural networks for single-channel speech separation", Signal and Information Processing (GlobalSIP), 2014 IEEE Global Conference on, IEEE, 2014.

[wen_chime1] Weninger, Felix; Geiger, Jurgen; Wollmer, Martin; Schuller, Bjorn; Rigoll, Gerhard: "The Munich 2011 CHiME Challenge Contribution: BLSTM-NMF Speech Enhancement and Recognition for Reverberated Multisource Environments", CHiME 2011 Workshop on Machine Listening in Multisource Environments, Citeseer, 2011.

[pybrain_cite] Schaul, Tom; Bayer, Justin; Wierstra, Daan; Sun, Yi; Felder, Martin; Sehnke, Frank; Rückstieß, Thomas; Schmidhuber, Jürgen: "PyBrain", Journal of Machine Learning Research, JMLR. org, 2010. 

[theano_cite1] Bastien, Frederic; Lamblin, Pascal; Pascanu, Razvan; Bergstra, James; Goodfellow, Ian; Bergeron, Arnaud; Bouchard, Nicolas; Warde-Farley, David; Bengio, Yoshua : "Theano: new features and speed improvements", arXiv preprint arXiv:1211.5590, 2012.

[theano_cite2] Bergstra, James; Breuleux, Olivier; Bastien, Frederic; Lamblin, Pascal; Pascanu, Razvan; Desjardins, Guillaume; Turian, Joseph; Warde-Farley, David; Bengio, Yoshua : "Theano: a CPU and GPU math expression compiler", Proceedings of the Python for scientific computing conference, SciPy, 2010.

[torch7_cite] Collobert, Ronan; Kavukcuoglu, Koray; Farabet, Clement: "Torch7: A matlab-like environment for machine learning", BigLearn, NIPS Workshop, 2011.

[wen_currennt_cite] Weninger, Felix; Bergmann, Johannes; Schuller, Bjorn: "Introducing CURRENNT: The Munich Open-Source CUDA RecurREnt Neural Network Toolkit", Journal of Machine Learning Research, 2015.

[rnnlib] Alex Graves, RNNLIB: A recurrent neural network library for sequence learning problems, http://sourceforge.net/projects/rnnl/, 25.6.2015

[cuda-cite] "Parallel Programming and Computing Platform - CUDA - NVIDIA", http://www.nvidia.com/object/cuda_home_new.html, 25.6.2015

[graves_blstm] Graves, Alex: "Supervised Sequence Labelling with Recurrent Neural Networks", Springer, http://www.cs.toronto.edu/~graves/preprint.pdf, 2012., str. 20, 21, 26

[wen_currennt_README] "CURRENNT README", sourceforge.net/projects/currennt/, 25.6.2015

[test_val] Elkan, Charles: "Evaluating Classifiers", 20.1.2012, http://cseweb.ucsd.edu/~elkan/250Bwinter2012/classifiereval.pdf, 25.6.2015

[wen_opensmile_cite] Eyben, Florian; Weninger, Felix; Gross, Florian; Schuller, Bjoern: "Recent developments in opensmile, the munich open-source multimedia feature extractor", Proceedings of the 21st ACM international conference on Multimedia, ACM, 2013.

[wen_currennt_tools_README] "CURRENNT tools README", sourceforge.net/projects/currennt/, 25.6.2015

[github_nc_packer] Henc, Stjepan: "Scripts for creating netCDF databases for CURRENNT", https://github.com/sthenc/nc_packer, 25.6.2015

[chime_website] "The 2nd 'CHiME' Speech Separation and Recognition Challenge: Medium vocabulary track", http://spandh.dcs.shef.ac.uk/chime_challenge/chime2013/chime2_task2.html, 25.6.2015

[NetCDF] "Network Common Data Form (NetCDF)", http://www.unidata.ucar.edu/software/netcdf/, 25.6.2015

